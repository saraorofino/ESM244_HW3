---
title: "ESM 244 HW 3"
author: "Sara Orofino"
date: "3/5/2019"
output: 
  html_document:
  css: custom.css
  toc: true
---
#{.tabset}

```{r setup, include=FALSE, message = FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(tseries)
library(forecast)
library(sf)
library(tmap)
library(leaflet)
library(ggrepel)
library(ggspatial)
library(RColorBrewer)
library(ggthemes)
library(raster)
library(effsize)
library(naniar)
library(latex2exp)
```

##Task 1 

Open science’s most important goals are to make scientific research more transparent and accountable. The open science movement lies on a foundational belief that scientific research across all fields shouldn’t occur in isolation, but rather be conducted as a part of a larger dialogue with society. Studies indicate that open science can have many benefits to researchers including identification and connection to potential collaborators, increased probability of being cited, higher levels of media attention, and additional funding opportunities.   

Despite the tangible benefits to the scientific community and the general public, attainment of open science goals is hindered by the all or nothing approach. With respect to implementation, the all or nothing approach sacrifices progress towards attaining the goals of open science for the idea of achieving perfectly open science. Instead of celebrating the progress that is being made, scientists are often criticized for failure to fully implement all open science practices. Without recognition of progress and a feeling of support from the open science community, there is little incentive for scientists to continue making the changes required to attain open science goals. These criticisms don’t respect the advancements that scientists have made toward removing barriers to open science and makes the open science community feel more exclusive.    

Open science is further inhibited by its failure to recognize the systematic barriers to accessibility and the inherent inequity of those barriers. The resistance to open data stems from legitimate concerns by those who may be disproportionately impacted by the accessibility barriers but are often disparaged by those who do not share the same concerns. These tend to be scientists who are early in their career, have lower job security, are from developing countries, or working for institutions with less financial resources. This portion of the scientific community may experience an unequal financial and/or social burden to accessing open science. For example, publishing costs can pose a significant barrier to scientists who are from developing countries or those working for institutions with less financial resources. Junior scientists or early career scientists may fear retaliation from senior colleagues when participating in open review. Additionally, there is a persisting perception among the scientific community that open science journals are less prestigious. Younger career scientists may be concerned about how publishing in these types of journals will reflect on the quality of their research and their potential job prospects. Recognizing the validity in these concerns and taking steps to address them in a way that prioritizes equitable access and creates an inclusive community will be necessary for open science to succeed.     

As I enter the world of data science I am learning to implement practices that will contribute to the goals of open science. To allow for transparency and reproducibility in my research I am using GitHub, the open online version control platform. By creating public repositories for my research I am allowing collaborators, faculty research advisors, and clients to view my data, code, and decision-making process. By annotating my code and documenting the process of my work I am ensuring that it is reproducible as well. One area I could improve on moving forward is organizing my documentation during the initial process of exploring and understanding data. As I’ve been working with two colleagues on a class project, we have all created separate documents for exploring the data and trying different maps and graphs. Having several different documents all containing parts of the code we need has made it difficult to put our project together in a cohesive way that is easy to reproduce and understand. Moving forward, especially into my group project work over the next year, I believe that it will be critical to have a better documentation and organization of even the preliminary and exploratory research that feeds into our analysis and final project outcomes.   


##Task 2

###Truckee River Flows

a. Create timeseries data and visualize decomposed data:  

```{r, message=FALSE, fig.align="center"}

truckee <- read_csv("truckee_flow.csv")

# Convert to ts data
truckee_ts <- ts(truckee$mean_flow, frequency = 12, start = c(2000,1))

#Visualize initial time series:
#plot(truckee_ts)

# Decompose ts data:
truckee_dc <- decompose(truckee_ts)

#Visualize it:
plot(truckee_dc)


```

**Time Series Description:**    
The time series looks additive and there does not seem to be an overall trend. There is some seasonality to the data but the scale of the seasonality is about 1/6th of the scale of the observed time series so the effect might not be as strong as it looks in the seasonality component of the time series graph. There does appear to be a larger cycle in approximately 5 year intervals where the data peaks within about a year and then decreases to a minimum (of that interval) by the end of the 5 year period.   


b. Holt-Winters and ARIMA for forecasting:    

```{r, fig.align="center"}

########### Holt-winters:

truckee_hw <- HoltWinters(truckee_ts)
#plot(truckee_hw)

# Forecast:
truckee_forecast_hw <- forecast(truckee_hw, h = 60)
#plot(truckee_forecast_hw)


########### ARIMA:

# Find pdq with auto arima:
truckee_pdq <- auto.arima(truckee_ts)
#truckee_pdq

# Non-seasonal (2,1,1)
# Seasonal (0,0,2)

# Fit ARIMA with pdq inputs:
truckee_arima <- arima(truckee_ts, order = c(2,1,1), seasonal = list(order = c(0,0,2)))

# Forecast ARIMA:
truckee_forecast_arima <- forecast(truckee_arima, h = 72)
#plot(truckee_forecast_arima)

# Graph of HW: 
plot(truckee_forecast_hw,
     ylab= TeX('Truckee River Flows ($ft^{3}/s$)'), 
     xlab = "Year") 
```


c. Model Residuals:    

```{r, fig.align = "center", warning=FALSE, message=FALSE}

# Residuals for HW model:
par(mfrow = c(1,2))
hist(truckee_forecast_hw$residuals) 
qqnorm(truckee_forecast_hw$residuals)


```



##Task 3
###Mapping California National Parks  

```{r, warning=FALSE, message=FALSE, fig.align="center"}
# Read in CA counties shapefile and set crs to WGS84:

ca_counties <- read_sf(".", layer = "california_county_shape_file")
st_crs(ca_counties) = 4326 


# Read in NPS data and set crs to WGS84:
ca_nps <- read_sf(".", layer = "nps_boundary") %>% 
  filter(STATE == "CA", UNIT_TYPE == "National Park") %>% 
  dplyr::select(UNIT_NAME, PARKNAME) %>% 
  mutate(lon=map_dbl(geometry, ~st_centroid(.x)[[1]]), 
         lat=map_dbl(geometry, ~st_centroid(.x)[[2]]))

st_crs(ca_nps) = 4326

# Change NA value for ParkName to Redwoods
ca_nps[is.na(ca_nps)]<-"Redwood"

# Clip off the Nevada part of Death Valley National Park 
nps_clip <- st_intersection(ca_nps, ca_counties)

# CA National Parks graph:
ggplot(ca_counties) +
  geom_sf(fill = "cornsilk2",
          color  = "grey10",  
          size =  0.1) +
  geom_sf(data = nps_clip, fill= "darkgreen") +
  geom_label_repel(data=ca_nps, aes(x=lon, y=lat, label=PARKNAME),
                  box.padding = 0.80, 
                  point.padding = 0.5,
                  alpha = 0.75,
                  fontface = 'bold', 
                  color = 'black') +
  theme_bw() +
  theme(panel.grid.major = element_line(colour = 'transparent'),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank()) +
  labs(x = "", y = "",
       title = "California National Parks")
```


##Task 4
###Lizards in the Northern Chihuahuan Desert 


a. For all lizards trapped at site ‘CALI’, do weights of male and female adult lizards differ
significantly?  

```{r warning=FALSE, message=FALSE}

# Read in data set filter for adult male and female lizards at site 'CALI' (use for both tests)
lizard <- read_csv("lizard_clean.csv") %>% 
  filter(site == "CALI") %>% 
  filter(sex == "M" | sex == "F") %>% 
  replace_with_na_all(condition = ~.x == ".")

# Make weights numeric 
lizard$weight <- as.numeric(lizard$weight)

# Subset data for just male only and female only to visualize distributions 

lizard_male <- lizard %>%
  filter(sex == "M", weight != "NA") 

lizard_female <- lizard %>%
  filter(sex == "F", weight != "NA") 


# Visualize distributions with histograms  

#ggplot(lizard_male, aes(x=weight)) +
  #geom_histogram()

#ggplot(lizard_female, aes(x=weight)) +
  #geom_histogram()

# Both are skewed but sample sizes are over 30 so CLT says means will be evenly distributed 

########## Hypothesis Testing ###############
# Run F-test for equal variances
# HO: Variances are equal (ratio of variances = 1)
# HA: Variances are not equal (ratio of variances ≠ 1)
lizard_ftest <- var.test(weight ~ sex, data = lizard)

# Results - retain the null (p-value = 0.2938) variances are equal 

# Run an upaired t-test to determine if weights are significantly different between males and females: 
# H0: Mean weights are equal    
# HA: Mean weights are not equal  
lizard_ttest <- t.test(weight ~ sex, data = lizard, var.equal = TRUE)

# Results - Mean weights are not significantly different t(130) = 0.79647; p-value = 0.4272 

# Actual mean weights 
male_mean <- mean(lizard_male$weight) # 4.965
male_sd <- sd(lizard_male$weight) #5.679
female_mean <- mean(lizard_female$weight) # 5.826
female_sd <- sd(lizard_female$weight) #6.496

# Difference in mean weights:
mean_diff <- female_mean - male_mean
#0.862

#Effect size Cohen's D:
lizard_eff <- cohen.d(weight ~ sex, data = lizard)
# Negligible Cohens D = -0.14
```

Mean adult female lizard (5.83 g ± 6.50 g, n = 75) and male lizard (4.97 g ± 5.68 g, n = 57) body mass did not differ significantly [t(`r lizard_ttest$parameter`) = `r round(lizard_ttest$statistic, 2)`, *p* = `r round(lizard_ttest$p.value, 3)`, $\alpha$ = 0.05] and the actual difference in mean weight between female and male lizards is less than one gram with a negligible effect size (Cohen's D = -0.14). 

b. For lizards trapped at the ‘CALI’ site, is there a significant difference in the proportion of
adult male and female lizards with broken tails?    

```{r, warning=FALSE, message=FALSE}

# Chi square to test for differences in proportions 
#H0 - there is no difference in proportion of males and females with broken tails
#HA - there IS a difference in proportion of males and females with broken tails 

lizard_chi <- lizard %>% 
  dplyr::select(sex, tail) %>% 
  filter(tail != "NA") %>% 
  count(sex, tail) %>% 
  spread(tail, n) %>% 
  dplyr::select(-sex)
  
row.names(lizard_chi) <- c("F", "M")

#Perform chi-square 

lizard_x2test <- chisq.test(lizard_chi) 

# NOT a significant difference in proportions X2(1) = 0.30857, p-value = 0.5786

# Proportions for reporting:
# Total male - 56
# Total female - 77
male_broken <- 10/56 #0.179
female_broken <- 18/77 #0.234


```

There is not a significant difference in the proportion of adult male (0.18) and female (0.23) lizards with broken tails [$x^2$ = (`r lizard_x2test$parameter`) = `r round(lizard_x2test$statistic, 2)`, *p* = `r round(lizard_x2test$p.value, 3)`].  

